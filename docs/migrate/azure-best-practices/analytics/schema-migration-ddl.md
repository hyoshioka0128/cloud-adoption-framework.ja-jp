---
title: スキーマ移行のデータ定義言語
description: Azure Synapse Analytics にスキーマを移行する場合の、データ定義言語 (DDL) の設計上の考慮事項とパフォーマンス オプションについて説明します。
author: v-hanki
ms.author: brblanch
ms.date: 07/14/2020
ms.topic: conceptual
ms.service: cloud-adoption-framework
ms.subservice: migrate
ms.custom: think-tank
ms.openlocfilehash: 8f8656992f3e604914df07d4b59acaec62b92d13
ms.sourcegitcommit: b8f8b7631aabaab28e9705934bf67dad15e3a179
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 03/03/2021
ms.locfileid: "101785599"
---
<!-- cSpell:ignore DDLs Attunity "Attunity Replicate" "Attunity Visibility" Inmon Denodo DMVs multinode equi Datometry -->

# <a name="data-definition-languages-for-schema-migration"></a>スキーマ移行のデータ定義言語

この記事では、Azure Synapse Analytics にスキーマを移行する場合の、データ定義言語 (DDL) の設計上の考慮事項とパフォーマンス オプションについて説明します。

## <a name="design-considerations"></a>設計上の考慮事項

### <a name="preparation-for-migration"></a>移行の準備

既存のデータを Azure Synapse Analytics に移行する準備を行う場合、演習の範囲を明確に定義することが重要です (特に初期移行プロジェクトの場合)。 前もって時間を取り、データベース オブジェクトと関連プロセスがどのように移行されるかを理解することで、その後のプロジェクトでの労力とリスクの両方を減らすことができます。

移行するデータベース オブジェクトのインベントリを作成します。 ソース プラットフォームに応じて、このインベントリには次のオブジェクトの一部またはすべてが含まれます。

- テーブル
- Views
- Indexes
- 関数
- ストアド プロシージャ
- データ分散とパーティション分割

これらのオブジェクトの基本情報には、行数、物理サイズ、データ圧縮率、オブジェクトの依存関係などのメトリックが含まれている必要があります。 この情報は、ソース システム内のシステム カタログ テーブルに対するクエリを通じて利用できる必要があります。 システム メタデータは、この情報の最適なソースです。 外部のドキュメントは、情報が古くなっており、初期の実装以降にデータ構造に適用された変更と同期していない可能性があります。

また、クエリ ログから実際のオブジェクトの使用状況を分析したり、作業に役立つ Microsoft パートナーのツール (Attunity Visibility など) を使用したりすることもできます。 一部のテーブルは、実稼働クエリで使用されなくなったため、移行する必要がない場合があります。

Azure Synapse Analytics では、データ サイズとワークロードの情報が重要です。これは、適切な構成を定義するのに役立つためです。 一例として、必要な同時実行のレベルがあります。 予想されるデータとワークロードの増加について理解することが、推奨されるターゲット構成に影響を与える可能性があります。また、この情報を活用することをお勧めします。

新しいターゲット プラットフォームに必要なストレージを見積もるためにデータ ボリュームを使用するときには、ソース データベースのデータ圧縮率 (圧縮している場合) を理解することが重要です。 ソース システムで使用されているストレージの量をそのまま使用すると、サイズ設定の根拠を誤る可能性があります。 監視およびメタデータ情報は、現在のシステムの圧縮されていない生データのサイズ、およびインデックス作成、データ レプリケーション、ログ記録、あるいは他のプロセスのオーバーヘッドを判別するのに役立ちます。

移行する必要のあるテーブルの圧縮されていない生データ サイズは、新しいターゲット Azure Synapse Analytics 環境で必要とされるストレージを見積もる際に最初に考慮することをお勧めします。

新しいターゲット プラットフォームには、圧縮率とインデックス作成のオーバーヘッドも含まれますが、これらはソース システムとは異なる可能性があります。 Azure Synapse Analytics のストレージ価格には、7 日間のスナップショット バックアップも含まれています。 既存の環境と比較すると、これは必要なストレージの全体的なコストに影響を与える可能性があります。

データ モデルのパフォーマンス チューニングは、移行プロセスの終盤まで遅らせ、データ ウェアハウスに実際のデータ ボリュームが存在するようになってから行うことができます。 しかし、いくつかのパフォーマンス チューニング オプションはもっと早い段階で実装することをお勧めします。

たとえば、Azure Synapse Analytics では、小さいディメンション テーブルをレプリケート テーブルとして定義し、大きいファクト テーブルをクラスター化列ストア インデックスとして定義するのが理にかなっています。 同様に、ソース環境で定義されたインデックスは、新しい環境でインデックスを作成することからメリットが得られる可能性のある列を判断するのに役立ちます。 テーブルを読み込む前に最初に定義するときにこの情報を使用すると、プロセスの後半で時間を節約できます。

Azure Synapse Analytics で使用するデータの圧縮率やインデックス オーバーヘッドは、移行プロジェクトの進行に応じて測定することをお勧めします。 この測定を基に、将来的なキャパシティ プランニングを行うことができます。

移行を容易にするために複雑さを軽減することで、移行前に既存のデータ ウェアハウスを簡素化できる場合があります。 この作業には次のようなものがあります。

- 未使用のテーブルを移行前に削除またはアーカイブして、使用されていないデータを移行しないようにします。 データを Azure Blob Storage にアーカイブして外部テーブルとして定義すると、そのデータを使用できる状態に維持してコストを削減できます。
- データ仮想化ソフトウェアを使用して物理データ マートを仮想データ マートに変換し、移行する必要があるものを減らします。 この変換によって機敏性が向上し、総保有コストも削減されます。 これは、移行時の最新化と見なすことができます。

移行演習の目的の 1 つは、基になるデータ モデルを変更することによって、ウェアハウスも最新化することです。 一例として、Inmon スタイルのデータ モデルからデータ コンテナー アプローチへの移行があります。 これは準備フェーズの一部として決定し、その切り替え戦略を移行計画に組み込む必要があります。

このシナリオで推奨されるアプローチは、最初にデータ モデルをそのまま新しいプラットフォームに移行してから、Azure Synapse Analytics で新しいモデルに切り替えることです。 プラットフォームのスケーラビリティとパフォーマンスの特性を活かし、ソース システムに影響を与えずに変換を実行します。

### <a name="data-model-migration"></a>データ モデルの移行

ソース システムのプラットフォームとオリジンによっては、一部またはすべての部分のデータ モデルが既にスター スキーマまたはスノーフレーク スキーマ形式になっている場合があります。 その場合、それはそのまま Azure Synapse Analytics に直接移行できます。 このシナリオは、実現できる最も簡単で最もリスクの低い移行です。 現状のままで行う移行は、前述のデータ コンテナーなどの、基になる新しいデータ モデルへの切り替えを含む、より複雑な移行の最初の段階でもあります。

リレーショナル テーブルとビューのセットはすべて、Azure Synapse Analytics に移行できます。 大規模なデータ セットに対する分析クエリ ワークロードの場合、一般的にスターまたはスノーフレーク データ モデルを使用すると、全体的に最高のパフォーマンスが得られます。 ソース データ モデルがまだこの形式になっていない場合は、移行プロセスを使用してモデルを再エンジニアリングする価値があることがあります。

移行プロジェクトにデータ モデルへの変更が含まれている場合は、新しいターゲット環境でこれらの変更を実行することをお勧めします。 つまり、最初に既存のモデルを移行してから、Azure Synapse Analytics の能力と柔軟性を活かし、データを新しいモデルに変換します。 この方法で実行すると、既存のシステムへの影響を最小限に抑えつつ、Azure Synapse Analytics のパフォーマンスとスケーラビリティを利用して、変更を迅速かつコスト効率よく行うことができます。

既存のシステムを複数のレイヤー (データの取り込みまたはステージング レイヤー、データ ウェアハウス レイヤー、レポートやデータ マート レイヤーなど) として移行することができます。 各レイヤーは、リレーショナル テーブルおよびビューで構成されます。 これらをすべてそのまま Azure Synapse Analytics に移行することはできますが、Azure エコシステムの特性と機能の一部を活用する方がコスト効率と信頼性が向上する可能性があります。 次に例を示します。

- **データの取り込みとステージング:** ETL (抽出、変換、読み込み) または ELT (抽出、読み込み、変換) プロセスの一部で、リレーショナル テーブルではなく、並列データの高速読み込みを実現する PolyBase と Azure Blob Storage を併用することができます。
- **レポート レイヤーとデータ マート:** Azure Synapse Analytics のパフォーマンス特性によって、レポート目的やデータ マート用に集計されたテーブルを物理的にインスタンス化する必要がなくなる可能性があります。 これらをビューとしてコア データ ウェアハウスに実装したり、サードパーティのデータ仮想化レイヤー経由で実装したりすることも可能なことがあります。 基本レベルでは、履歴データのデータ移行プロセスと、場合によっては増分更新を、この図に示されているように実現できます。

   ![最新のデータ ウェアハウスを示す図。](../../../_images/analytics/schema-migration-ddl.png)

これらの方法や同様の方法を使用できる場合、移行するテーブルの数が減ります。 一部のプロセスは簡略化または除外される可能性があるため、移行ワークロードも減ります。 これらの方法を適用できるかどうかは、個々のユース ケースによって異なります。 しかし、一般的な原則は、移行ワークロードを減らし、コスト効率の高いターゲット環境を構築するために、可能な限り、Azure エコシステムの特性と機能を活用することを検討することです。 これは、バックアップまたは復元、ワークフローの管理や監視などの他の機能にも当てはまります。

Microsoft パートナーから提供されている製品やサービスが、データ ウェアハウスの移行や、場合によってはプロセスの一部の自動化に役立ちます。 既存のシステムにサードパーティの ETL 製品が組み込まれている場合、ターゲット環境として Azure Synapse Analytics が既にサポートされている可能性があります。 既存の ETL ワークフローは、新しいターゲットのデータ ウェアハウスにリダイレクトできます。

### <a name="data-marts-physical-or-virtual"></a>データ マート:物理データ マートと仮想データ マート

古いデータ ウェアハウス環境を使用する組織では、その部門やビジネス機能に適切なアド ホック セルフサービス クエリおよびレポート パフォーマンスを提供するデータ マートを作成するのが一般的です。 データ マートは通常、元のデータの集計されたバージョンを含むデータ ウェアハウスのサブセットで構成されます。 この形式 (通常は次元データ モデル) の場合、ユーザーは簡単にデータに対してクエリを実行でき、Tableau、MicroStrategy、Microsoft Power BI などのユーザー フレンドリなツールから受け取る応答の時間が短くなります。

データ マートの使用方法の 1 つは、基になるウェアハウス データ モデルが異なる (データ コンテナーなど) 場合でも、使用可能な形式でデータを公開することです。 この方法は、3 層モデルとも呼ばれます。

組織内の個々の事業単位に個別のデータ マートを使用して、堅牢なデータ セキュリティ体制を実装することができます。 たとえば、関連する特定のデータ マートへのユーザーのアクセスを許可し、機密データを除外、難読化、または匿名化することができます。

これらのデータ マートが物理テーブルとして実装されている場合は、それらを格納するための追加のストレージ リソースと、それらを定期的にビルドおよび更新するための追加の処理が必要になります。 物理テーブルは、マート内のデータは最後の更新操作時点での最新の状態が保たれているにすぎないため、変動の激しいデータ ダッシュボードには適していない可能性があることを示しています。

Azure Synapse Analytics などの比較的安価でスケーラブルな超並列処理 (MPP) アーキテクチャの出現とそれらに固有のパフォーマンス特性により、マートを物理テーブルのセットとしてインスタンス化しなくても、データ マート機能を提供できる場合があります。 これを実現するには、これらの方法のいずれかを使用してデータ マートを効果的に仮想化します。

- メイン データウェア ハウスの SQL ビュー。
- Azure Synapse Analytics やサードパーティの仮想化製品 (Denodo など) のビューなどの機能を使用する仮想化レイヤー。

このアプローチにより、ストレージと集計処理が簡素化されるか、必要性がなくなります。 これにより、移行されるデータベース オブジェクトの全体的な数が減ります。

データ ウェアハウス アプローチのもう 1 つの利点は、大量のデータ ボリュームに対する結合や集計などの操作を実行するための容量です。 たとえば、仮想化レイヤー内に集計および結合ロジックを実装し、仮想化されたビューで外部レポートを表示すると、データ ウェアハウスにこれらのビューを作成するために必要な堅牢な処理がプッシュされます。

物理データ マートと仮想データ マートのどちらを実装するかを選択するための主な要素を以下に示します。

- 機敏性が向上する。 仮想データ マートの方が、物理テーブルとその関連 ETL プロセスよりも変更しやすい。
- 仮想化された実装でデータ ストアとデータのコピーが少なくなるため、総保有コストを削減できる。
- 移行のための ETL ジョブが除外され、仮想化環境のデータ ウェアハウス アーキテクチャが簡素化される。
- パフォーマンス。 これまでのところ、物理データ マートの方が信頼性が高い。 これを緩和するために、インテリジェントなキャッシュ技法が仮想化製品に実装されるようになっている。

データの仮想化を使用して、移行プロジェクト中に一貫してユーザーにデータを表示することもできます。

### <a name="data-mapping"></a>データ マッピング

#### <a name="key-and-integrity-constraints-in-azure-synapse-analytics"></a>Azure Synapse Analytics のキーと整合性の制約

主キーおよび外部キーの制約は、Azure Synapse Analytics 内では現在適用されていません。 しかし、`NOT ENFORCED` 句を使用して、`PRIMARY KEY` の定義を `CREATE TABLE` ステートメントに含めることができます。 これは、サードパーティのレポート製品で、データ モデル内のキーを解釈して最も効率的なクエリを生成するために、テーブルのメタデータを使用できることを意味しています。

#### <a name="data-type-support-in-azure-synapse-analytics"></a>Azure Synapse Analytics のデータ型サポート

一部の古いデータベース システムには、Azure Synapse Analytics によって直接サポートされていないデータ型のサポートが含まれています。 これらのデータ型は、サポートされているデータ型を使用してデータをそのまま格納するか、サポートされているデータ型にデータを変換することによって処理できます。

サポートされているデータ型の一覧をアルファベット順で以下に示します。

<!-- TODO: Review format of this list. Are the arguments necessary for this list? -->

- `bigint`
- `binary [ (n) ]`
- `bit`
- `char [ (n) ]`
- `date`
- `datetime`
- `datetime2 [ (n) ]`
- `datetimeoffset [ (n) ]`
- `decimal [ (precision [, scale ]) ]`
- `float [ (n) ]`
- `int`
- `money`
- `nchar [ (n) ]`
- `numeric [ (precision [ , scale ]) ]`
- `nvarchar [ (n | MAX) ]`
- `real [ (n) ]`
- `smalldatetime`
- `smallint`
- `smallmoney`
- `time [ (n) ]`
- `tinyint`
- `uniqueidentifier`
- `varbinary [ (n | MAX) ]`
- `varchar [ (n | MAX) ]`

次の表には、現在サポートされていない一般的なデータ型が一覧表示されており、それらを Azure Synapse Analytics に格納するために推奨される方法も示されています。 Teradata や Netezza などの特定の環境の詳細については、関連するドキュメントを参照してください。

| サポートされていないデータ型 | 回避策 |
|--|--|
| `geometry` | `varbinary` |
| `geography` | `varbinary` |
| `hierarchyid` | `nvarchar(4000)` |
| `image` | `varbinary` |
| `text` | `varchar` |
| `ntext` | `nvarchar` |
| `sql_variant` | 列を厳密に型指定された複数の列に分割 |
| `table` | 一時テーブルに変換 |
| `timestamp` | `datetime2` と `CURRENT_TIMESTAMP` 関数を使用するようにコードを再作成 |
| `xml` | `varchar` |
| ユーザー定義型 | 可能な場合は、ネイティブ データ型に戻す |

#### <a name="potential-data-issues"></a>潜在的なデータの問題

ソース環境によっては、データの移行時に問題の原因となる可能性がある問題がいくつかあります。

- 異なるデータベース製品で `NULL` データが処理される方法には、微妙な違いがあります。 例として、照合順序や空の文字列の処理などがあります。
- `DATE`、`TIME`、`INTERVAL`、`TIME ZONE` データと関連する関数は、製品によって大きく異なる場合があります。

これらを徹底的にテストし、ターゲット環境で目的の結果が得られるかどうかを判断してください。 移行の演習により、現在、既存のソース システムの一部になっているバグや正しくない結果が明らかになる場合があり、移行プロセスは異常を修正する絶好の機会です。

#### <a name="best-practices-for-defining-columns-in-azure-synapse-analytics"></a>Azure Synapse Analytics での列の定義に関するベスト プラクティス

古いシステムには、非効率的なデータ型の列が含まれているのが一般的です。 たとえば、実際のデータ値が `CHAR(5)` フィールドに収まる場合に、`VARCHAR(20)` として定義されたフィールドがある可能性があります。 あるいは、すべての値が `SMALLINT` フィールドに収まる場合に、`INTEGER` フィールドが使用されている可能性があります。 データ型が不十分である場合、特に大規模なファクト テーブルでは、ストレージとクエリの両方のパフォーマンスが低下する可能性があります。

移行の演習時に、現在のデータ定義を確認し、合理化することをお勧めします。 これらのタスクは、SQL クエリを使用してデータ フィールド内の最大の数値や文字長を検索し、その結果をデータ型と比較することによって自動化できます。

一般的には、テーブルに対して定義されている行の長さの合計を最小限に抑えることをお勧めします。 最適なクエリ パフォーマンスを得るために、前述のように、列ごとに最小のデータ型を使用ですることができます。 Azure Synapse Analytics で外部テーブルからデータを読み込む場合は、PolyBase ユーティリティを使用することをお勧めします。このユーティリティによって、定義される行の最大長として 1 メガバイト (MB) がサポートされています。 1 MB より長い行を含むテーブルは、PolyBase によって読み込まれません。代わりに [bcp](/sql/tools/bcp-utility?view=sql-server-ver15) を使用する必要があります。

結合を最も効率的に実行するには、結合の両側の列を同じデータ型として定義します。 ディメンション テーブルのキーが `SMALLINT` として定義されている場合は、そのディメンションを使用するファクト テーブルの対応する参照列も `SMALLINT` として定義する必要があります。

文字フィールドは既定のサイズを大きく定義しないでください。 フィールド内のデータの最大サイズが 50 文字の場合は、`VARCHAR(50)` を使用します。 同様に、`VARCHAR` で十分な場合は `NVARCHAR` を使用しないでください。 `NVARCHAR` の場合、さまざまな言語の文字セットを使用できるように、Unicode データが格納されます。 `VARCHAR` の場合は、ASCII データが格納されるため、スペースが少なくて済みます。

## <a name="summary-of-design-recommendations"></a>設計上の推奨事項の概要

不要なオブジェクトやプロセスは移行しないようにします。 移行するオブジェクトやプロセスの実際の数を減らすのが適している場合は、ターゲットの Azure 環境の組み込み機能と関数を使用します。 移行する物理データ マートの数を減らすかなくして、データ ウェアハウスに処理をプッシュ ダウンするために仮想化レイヤーの使用を検討してください。

可能な限り自動化し、ソース システムのシステム カタログのメタデータを使用して、ターゲット環境の DDL を生成します。 可能であれば、ドキュメントの生成も自動化します。 WhereScape などの Microsoft パートナーは、自動化を支援するための特別なツールやサービスを提供できます。

必要なデータ モデルの変更やデータ マッピングの最適化は、ターゲット プラットフォーム上で実行します。 Azure Synapse Analytics では、これらの変更をより効率的に行うことができます。 この方法により、キャパシティの限界ぎりぎりで既に実行している可能性のあるソース システムに対する影響を軽減できます。

## <a name="performance-options"></a>パフォーマンス オプション

このセクションでは、データ モデルのパフォーマンスを向上させるために Azure Synapse Analytics 内で使用できる機能について説明します。

### <a name="general-approach"></a>一般的なアプローチ

プラットフォームの機能によって、移行されるデータベースのパフォーマンス チューニングが実行されます。 このようなパフォーマンス チューニングの例としては、インデックス、データのパーティション分割、およびデータ分散があります。 移行を準備するときに、チューニングを文書化すると、Azure Synapse Analytics ターゲット環境で適用できる最適化を把握して判断できます。

たとえば、テーブルに一意でないインデックスが存在する場合、そのインデックスで使用されているフィールドが、フィルター処理、グループ化、または結合に頻繁に使用されていることを示している可能性があります。 これは新しい環境でも同様です。そのため、インデックスを作成するフィールドを選択する場合はこのことにご注意ください。 Teradata や Netezza などの特定のソース プラットフォームの移行の推奨事項については、個別のドキュメントで詳しく説明されています。

ターゲットの Azure Synapse Analytics 環境のパフォーマンスとスケーラビリティを活用して、データ分散などのさまざまなパフォーマンス オプションを試します。 代替アプローチの中から最適な選択肢を決定します (たとえば、大きなディメンション テーブルにレプリケートを使用するかハッシュ分散を使用するか)。 そのために外部ソースからデータを再読み込みする必要はありません。 Azure Synapse Analytics では、`CREATE TABLE AS SELECT` ステートメントを使用し、さまざまなパーティション分割オプションや分散オプションを指定してテーブルのコピーを作成することにより、比較的短時間で簡単に代替アプローチをテストできます。

Azure 環境に用意されている監視ツールを使用して、クエリがどのように実行され、どこでボトルネックが発生する可能性があるかを把握できます。 監視ダッシュボードや、自動化されたリソース管理とアラート処理を提供するサードパーティの Microsoft パートナーからツールを入手することもできます。

Azure Synapse Analytics の各 SQL 操作と、そのクエリで使用されるメモリや CPU などのリソースは、システム テーブルに記録されます。 一連の動的管理ビューを使用すると、この情報に簡単にアクセスできます。

以下のセクションでは、クエリ パフォーマンスをチューニングするための Azure SQL Data Warehouse 内の主要なオプションについて説明します。 既存の環境には、ターゲット環境での最適化に役立つ可能性がある情報が含まれます。

### <a name="temporary-tables"></a>一時テーブル

Azure Synapse Analytics では一時テーブルがサポートされており、それらが作成されたセッションでのみ表示されます。 これらはユーザー セッションの間は存在し、セッションの終了時に自動的に削除されます。

一時テーブルを作成するには、テーブル名の先頭にハッシュ文字 (`#`) を付けます。 次のセクションで説明されているように、一時テーブルでは、通常のインデックス作成および分散オプションをすべて使用できます。

一時テーブルには、以下に示すいくつかの制限があります。

- 名前を変更することはできません。
- 表示やパーティション分割は許可されていません。
- アクセス許可の変更は許可されていません。

一時テーブルは、通常、ETL または ELT 処理で使用され、一時的な中間結果が変換プロセスの一部として使用されます。

### <a name="table-distribution-options"></a>テーブル分散オプション

Azure Synapse Analytics は、複数の処理ノードにまたがって並列に実行することによってパフォーマンスとスケーラビリティを実現する、MPP データベース システムです。

複数ノード環境で SQL クエリを実行するための理想的な処理シナリオは、ワークロードのバランスを取り、すべてのノードで同じ量のデータが処理されるようにすることです。 このアプローチを使用すれば、クエリを満たすためにノード間で移動する必要があるデータの量を最小限に抑えるか、そのようなデータを除外することができます。

一般的な分析クエリで頻繁に集計が行われ、複数のテーブル間 (ファクト テーブルとディメンション テーブルの間など) で複数の結合が行われるため、理想的なシナリオを実現するのは困難な場合があります。

クエリの処理方法に影響を与える方法の 1 つは、Azure Synapse Analytics 内の分散オプションを使用して、各テーブルの個々のデータ行が格納される場所を指定することです。 たとえば、2 つの大きなテーブルがデータ列 `CUSTOMER_ID` に結合されているとします。 結合が実行されるたびに、`CUSTOMER_ID` 列を通じて 2 つのテーブルを分散すると、確実に結合の各側のデータが同じ処理ノードに併置済みとなるようにすることができます。 この方法を使用すれば、ノード間でデータを移動する必要がなくなります。 テーブルの分散指定は、`CREATE TABLE` ステートメントで定義されます。

以下のセクションでは、使用可能な分散オプションと、それらを使用するタイミングに関する推奨事項について説明します。 必要に応じて、`CREATE TABLE AS SELECT` ステートメントを使用し、新しい分散を指定してテーブルを再作成すると、初期読み込み後にテーブルの分散を変更することができます。

#### <a name="round-robin"></a>ラウンド ロビン

ラウンド ロビン テーブル分散は既定のオプションであり、システム内のノード間にデータが均等に分散されます。 この方法は、データの高速読み込みの場合や、ボリュームが比較的少なく、ハッシュの明確な候補がないデータの場合に適しています。 これは、ETL または ELT プロセスの一部としてステージング テーブルに頻繁に使用されます。

#### <a name="hashed"></a>ハッシュ

前述の例の `CUSTOMER_ID` などのユーザー定義のキーに適用されたハッシュ アルゴリズムに基づいて、システムによって行がハッシュ バケットに割り当てられます。 その後、バケットが特定のノードに割り当てられ、同じ値でハッシュ分散されたすべてのデータ行が同じ処理ノードに存在することになります。

この方法は、キーで頻繁に結合または集計される大きなテーブルの場合に便利です。 結合する他の大きなテーブルは、可能であれば同じキーでハッシュする必要があります。 ハッシュ キーの候補が複数存在する場合は、最も頻繁に結合されるものを選択します。

ハッシュ列に null 値を含めることはできません。また、多くのクエリにより日付でフィルター処理が行われるため、通常は日付ではありません。 ハッシュするキーが `CHAR` や `VARCHAR` ではなく整数値である場合、通常はハッシュの方が効率的です。 少数のキー値がデータ行の大部分を表す場合など、値の範囲が非常に偏っているキーは選択しないようにしてください。

#### <a name="replicated"></a>レプリケート

テーブルの分散オプションとしてレプリケートを選択すると、クエリ処理の目的で、各コンピューティング ノードにそのテーブルの完全なコピーがレプリケートされます。

この方法は、比較的静的で、等結合によってより大きなテーブルに頻繁に結合される比較的小さなテーブル (通常は 2 GB 未満に圧縮されたもの) に役立ちます。 これらのテーブルは、多くの場合、スター スキーマ内のディメンション テーブルです。

### <a name="indexing"></a>インデックス作成

Azure Synapse Analytics には、レコードを取得するのに必要なリソースと時間を削減するために、大きなテーブルのデータにインデックスを付けるためのオプションが含まれています。

- クラスター化列ストア インデックス
- クラスター化インデックス
- 非クラスター化インデックス

どのインデックス オプションからもメリットが得られないテーブルには、`HEAP` という非インデックス オプションが存在します。 インデックスを使用すると、クエリ時間は短縮できますが、読み込み時間は長くなり、より多くのストレージ スペースが使用されることになります。 多くの場合、インデックスを使用すると、データ行のごく一部にのみ影響する大きなテーブルに対する `SELECT`、`UPDATE`、`DELETE`、`MERGE` の操作速度は向上します。また、完全なテーブル スキャンを最小限に抑えることができます。

`UNIQUE` 制約や `PRIMARY KEY` 制約が列に定義されると、インデックスが自動的に作成されます。

#### <a name="clustered-columnstore-index"></a>クラスター化列ストア インデックス

クラスター化列ストア インデックスは、Azure Synapse Analytics 内の既定のインデックス作成オプションです。 大きなテーブルに対して最適な圧縮とクエリのパフォーマンスが提供されます。 6,000 万行未満の小さなテーブルでは、これらのインデックスは効率的ではないため、`HEAP` オプションを使用する必要があります。 同様に、テーブル内のデータが一時的なもので、ETL または ELT プロセスの一部である場合は、ヒープまたは一時テーブルの方が効率的である可能性があります。

#### <a name="clustered-index"></a>クラスター化インデックス

強力なフィルター条件に基づいて、大きなテーブルから 1 行または少数の行を定期的に取得する必要がある場合、クラスター化列ストア インデックスよりもクラスター化インデックスを使用する方が効率的な可能性があります。 クラスター化インデックスは、各テーブルに 1 つだけ許可されます。

#### <a name="non-clustered-index"></a>非クラスター化インデックス

非クラスター化インデックスは、フィルター条件に基づいて 1 行または少数の行の取得を高速化できるという点で、クラスター化インデックスに似ています。 内部的に、非クラスター化インデックスはデータとは別に格納され、1 つのテーブルに対して複数の非クラスター化インデックスを定義できます。 ただし、インデックスを追加するたびにより多くのストレージが必要になり、データの挿入や読み込みのスループットは低下します。

#### <a name="heap"></a>ヒープ

ヒープ テーブルの場合、データの読み込み時にインデックスの作成と維持に関するオーバーヘッドは発生しません。 これは、ELT プロセスを含む、プロセス中に一時的なデータをすばやく読み込むのに役立ちます。 データがその後すぐに読み取られる場合は、キャッシュも役立ちます。 6,000 万行未満の場合、クラスター化列ストア インデックスは非効率的であるため、ヒープ テーブルは、行がこの数より少ないテーブルを格納するのにも役立ちます。

### <a name="data-partitioning"></a>データのパーティション分割

エンタープライズ データ ウェアハウスには、ファクト テーブルに数十億行が含まれる場合があります。 パーティション分割でこれらのテーブルを別々の部分に分割し、クエリ実行時に処理されるデータ量を減らすと、これらのテーブルの維持とクエリを最適化できます。 テーブルのパーティション分割指定は、`CREATE TABLE` ステートメントで定義されます。

パーティション分割に使用できるフィールドは、テーブルごとに 1 つだけです。 多くのクエリは日付または日付範囲でフィルター処理されるため、多くの場合、これは日付フィールドになります。 必要に応じて、`CREATE TABLE AS SELECT` ステートメントを使用し、新しい分散を指定してテーブルを再作成すると、初期読み込み後にテーブルのパーティション分割を変更することができます。

#### <a name="partitioning-for-query-optimization"></a>クエリを最適化するためのパーティション分割

大きいファクト テーブルに対するクエリが特定のデータ列によって頻繁にフィルター処理される場合、その列をパーティション分割することにより、クエリを実行するために処理する必要のあるデータ量を大幅に削減できます。 一般的な例としては、日付フィールドを使用して、小さいグループにテーブルを分割することが挙げられます。 各グループには 1 日のデータが含まれます。 日付でフィルター処理する `WHERE` 句がクエリに含まれている場合、その日付フィルターに一致するパーティションのみがアクセスされる必要があります。

#### <a name="partitioning-for-optimization-of-table-maintenance"></a>テーブルの維持を最適化するためのパーティション分割

データ ウェアハウス環境では、詳細なファクト データのローリング ウィンドウを維持するのが一般的です。 例として、5 年前までさかのぼる販売取引があります。 販売日を基にパーティション分割すると、ローリング ウィンドウを過ぎた古いデータの削除がはるかに効率的になります。 最も古いパーティションを削除する方が、個々のすべての行を削除するよりも速く、リソースの使用量が少なくなります。

### <a name="statistics"></a>統計

クエリは、Azure Synapse Analytics に送信されると、最初にクエリ オプティマイザーによって処理されます。 オプティマイザーによって、クエリを効率的に実行するための最適な内部メソッドが決定されます。

オプティマイザーにより、コストベースのアルゴリズムに基づいて使用できるさまざまなクエリ実行プランが比較されます。 コストの見積もりの精度は、使用可能な統計に依存します。 確実に統計が最新のものであるようにすることをお勧めします。

Azure Synapse Analytics では、`AUTO_CREATE_STATISTICS` オプションがオンになっていると、統計の自動更新がトリガーされます。 `CREATE STATISTICS` コマンドを使用して、手動で統計を作成または更新することもできます。

コンテンツが大幅に変更されている場合 (日次更新など) は、統計を更新してください。 この更新は、ETL プロセスに組み込むことができます。

データベース内のすべてのテーブルでは、少なくとも 1 つの列に統計が収集される必要があります。 これにより、行数やテーブル サイズなどの基本的な情報を確実にオプティマイザーで使用できるようになります。 統計が収集される必要のある他の列は、`JOIN`、`DISTINCT`、`ORDER BY`、`GROUP BY` の処理で指定されている列です。

### <a name="workload-management"></a>ワークロードの管理

Azure Synapse Analytics には、混合ワークロードのリソース使用率を管理するための包括的な機能が組み込まれています。 クエリとデータの負荷など、さまざまなワークロードの種類のリソース クラスを作成すると、ワークロードを管理するのに役立ちます。 同時に実行されるクエリの数と、各クエリに割り当てられているコンピューティング リソースに制限が設定されます。 メモリと同時実行の間にはトレードオフがあります。

- より小規模なリソース クラスでは、クエリごとの最大メモリは減りますが、同時実行は増えます。
- より大規模なリソース クラスでは、クエリごとの最大メモリは増えますが、同時実行は減ります。

### <a name="performance-recommendations"></a>パフォーマンスに関する推奨事項

インデックスやデータ分散などのパフォーマンス向上方法を使用して、新しいターゲット環境で同様の方法の候補を評価しますが、Azure Synapse Analytics で必要であることを確認するためにベンチマークを実行します。 確実に統計が最新のものであるようにするため、あるいは統計を自動作成することを選択するには、ETL または ELT プロセスに `COLLECT STATISTICS` ステップを構築します。

Azure Synapse Analytics で使用できるチューニング オプションと、並列データの高速読み込みを実現する PolyBase などの、関連するユーティリティのパフォーマンス特性を理解します。 これらのオプションを使用すると、効率的なエンドツーエンドの実装を構築できます。

Azure 環境の柔軟性、スケーラビリティ、およびパフォーマンスを利用して、データ モデルの変更やパフォーマンス チューニング オプションを適切に実装します。 この作業によって、既存のソース システムへの影響が軽減されます。

Azure Synapse Analytics で使用できる動的管理ビューについて理解します。 これらのビューによって、システム全体のリソース使用率に関する情報と、個々のクエリの詳細な実行情報の両方が提供されます。

Azure のリソース クラスについて理解し、それらを適切に割り当てて、混合ワークロードやコンカレンシーを効率的に管理できるようにします。

Azure Synapse Analytics 環境の一部として仮想化レイヤーを使用することを検討します。 ビジネス ユーザーやレポート ツールからウェアハウス実装の変更を保護することができます。

パートナー提供の移行ツールやサービス (Qlik Replicate for Microsoft Migrations、WhereScape、Datometry など) について調査します。 これらのサービスを使用すると、移行プロセスの一部を自動化して、移行プロジェクトに関係する経過時間やリスクを軽減できます。
